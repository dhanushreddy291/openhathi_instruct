{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8c5f6f32d174a3f8ed9a988209790c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e74fbf60a704f4d8bfa3c57b8b07d9a",
              "IPY_MODEL_c3c68480413447b48d406e4cf451fe22",
              "IPY_MODEL_2df13b1a0cc84e9cb6c11d073535f88a",
              "IPY_MODEL_ff2cd3bac24d4e6d8ed5933250d51dfb"
            ],
            "layout": "IPY_MODEL_92a3492f4b66436db6c5e9f82366efbc"
          }
        },
        "3f4bb617f8f44df4a6b8e2c201b05e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02bfd07164d344b4be2294d5dd336b74",
            "placeholder": "​",
            "style": "IPY_MODEL_eae8487ec51a4c518224e6f17740fbbf",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "bb0c02ed83bb42b6bd7f36c44aba4ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e39c4cbd8c1749638812f7f5db2a7e00",
            "placeholder": "​",
            "style": "IPY_MODEL_9a476c82774e45e4a3eae83f251892c0",
            "value": ""
          }
        },
        "d0bed69a0f934666b40792e92ea299ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_80c88cda35fd44e6880ee4e8a13c1094",
            "style": "IPY_MODEL_05f0c5e504174a06af727faf58a93fa3",
            "value": true
          }
        },
        "05dc6e4a5a884dd7aeed1aeeb1e96e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e17dba515ea64bbb9772aad5e9da4c1b",
            "style": "IPY_MODEL_a3e5b1def1774f7295ae95a7a2fbfa3a",
            "tooltip": ""
          }
        },
        "bd05d3ae520e40bdbaf700f479c64319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5e3db87cd144eb38ed7a17f65f42008",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf2b4eb227c440183eeffff156e514c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "92a3492f4b66436db6c5e9f82366efbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "02bfd07164d344b4be2294d5dd336b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae8487ec51a4c518224e6f17740fbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e39c4cbd8c1749638812f7f5db2a7e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a476c82774e45e4a3eae83f251892c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80c88cda35fd44e6880ee4e8a13c1094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f0c5e504174a06af727faf58a93fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17dba515ea64bbb9772aad5e9da4c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e5b1def1774f7295ae95a7a2fbfa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c5e3db87cd144eb38ed7a17f65f42008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf2b4eb227c440183eeffff156e514c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc87286ff9a84d3591e9fb2839dbcb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f289c7cbf6104263898142f100096e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_21e064d589604cf1bbd50261ae4fc260",
            "value": "Connecting..."
          }
        },
        "f289c7cbf6104263898142f100096e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e064d589604cf1bbd50261ae4fc260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e74fbf60a704f4d8bfa3c57b8b07d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6bb2f4480b4b1b94f7b4c5c6ab2b73",
            "placeholder": "​",
            "style": "IPY_MODEL_0feb00156d404f70b066d30e2d6f260c",
            "value": "Token is valid (permission: write)."
          }
        },
        "c3c68480413447b48d406e4cf451fe22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0def82f031b0483890bed3d87a9f5609",
            "placeholder": "​",
            "style": "IPY_MODEL_f5f81fd49ebf41e3b305abc4571a15ce",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "2df13b1a0cc84e9cb6c11d073535f88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f8186be8be462080e398683590d35f",
            "placeholder": "​",
            "style": "IPY_MODEL_e36a07262bae422c9a4f2642504ea203",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "ff2cd3bac24d4e6d8ed5933250d51dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb392d75a5c45ea9743955bbe1a18f0",
            "placeholder": "​",
            "style": "IPY_MODEL_873504ef77dd47d2aa9f74c338ecfb2a",
            "value": "Login successful"
          }
        },
        "0f6bb2f4480b4b1b94f7b4c5c6ab2b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0feb00156d404f70b066d30e2d6f260c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0def82f031b0483890bed3d87a9f5609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f81fd49ebf41e3b305abc4571a15ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f8186be8be462080e398683590d35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36a07262bae422c9a4f2642504ea203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcb392d75a5c45ea9743955bbe1a18f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873504ef77dd47d2aa9f74c338ecfb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFRVhWx9fUt",
        "outputId": "5bf9acf1-bdc0-4658-a59b-97c586391a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 22 05:01:58 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0              43W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pacman100/DHS-LLM-Workshop.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCJmgsuI90RZ",
        "outputId": "6de1ac22-b007-4fad-c28f-ad2c1dfd7e20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DHS-LLM-Workshop'...\n",
            "remote: Enumerating objects: 1351, done.\u001b[K\n",
            "remote: Counting objects: 100% (442/442), done.\u001b[K\n",
            "remote: Compressing objects: 100% (188/188), done.\u001b[K\n",
            "remote: Total 1351 (delta 311), reused 377 (delta 254), pack-reused 909\u001b[K\n",
            "Receiving objects: 100% (1351/1351), 45.63 MiB | 15.21 MiB/s, done.\n",
            "Resolving deltas: 100% (743/743), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install packaging\n",
        "!pip uninstall -y ninja && pip install ninja\n",
        "!ninja --version\n",
        "!echo $?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z9LKmFs90sv",
        "outputId": "ef24b441-da93-4a5e-c3f3-4e08776132d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
            "\u001b[33mWARNING: Skipping ninja as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n",
            "1.11.1.git.kitware.jobserver-1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DHS-LLM-Workshop\n",
        "!git pull\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF7Lz-G693ig",
        "outputId": "8ff9c317-f6a5-4e9a-f796-a91281d4ab72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS-LLM-Workshop\n",
            "Already up to date.\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-8gl_me_2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-8gl_me_2\n",
            "  Resolved https://github.com/huggingface/transformers to commit 3657748b4d1539ca89555f1cf2b465b74f445491\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/accelerate (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-gnwe046k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-gnwe046k\n",
            "  Resolved https://github.com/huggingface/accelerate to commit b565a6c58a0ef7df041cdd9742914ff9973e15a6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/huggingface/peft to /tmp/pip-req-build-6uuvby8i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-6uuvby8i\n",
            "  Resolved https://github.com/huggingface/peft to commit 993836ff90791289b94d27caa46385eec958e147\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/trl (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/trl to /tmp/pip-req-build-kq6ndt_c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-req-build-kq6ndt_c\n",
            "  Resolved https://github.com/huggingface/trl to commit 06b7959b72359bf32f314cb6c90c0bada2faba11\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.19.4)\n",
            "Collecting evaluate (from -r requirements.txt (line 6))\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 7))\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from -r requirements.txt (line 8))\n",
            "  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 9))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 10))\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from -r requirements.txt (line 11))\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.7.1)\n",
            "Collecting easyllm (from -r requirements.txt (line 16))\n",
            "  Downloading easyllm-0.6.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl==0.7.5.dev0->-r requirements.txt (line 4))\n",
            "  Downloading tyro-0.6.0-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r requirements.txt (line 5)) (4.5.0)\n",
            "Collecting dill (from evaluate->-r requirements.txt (line 6))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 6)) (3.4.1)\n",
            "Collecting multiprocess (from evaluate->-r requirements.txt (line 6))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate->-r requirements.txt (line 6))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.9.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 15)) (3.1.1)\n",
            "INFO: pip is looking at multiple versions of easyllm to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting easyllm (from -r requirements.txt (line 16))\n",
            "  Downloading easyllm-0.6.1-py3-none-any.whl (29 kB)\n",
            "  Downloading easyllm-0.6.0-py3-none-any.whl (29 kB)\n",
            "  Downloading easyllm-0.5.0-py3-none-any.whl (25 kB)\n",
            "  Downloading easyllm-0.4.0-py3-none-any.whl (23 kB)\n",
            "  Downloading easyllm-0.3.2-py3-none-any.whl (17 kB)\n",
            "  Downloading easyllm-0.3.1-py3-none-any.whl (17 kB)\n",
            "  Downloading easyllm-0.3.0-py3-none-any.whl (16 kB)\n",
            "INFO: pip is looking at multiple versions of easyllm to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading easyllm-0.2.0-py3-none-any.whl (11 kB)\n",
            "  Downloading easyllm-0.1.0-py3-none-any.whl (10 kB)\n",
            "  Downloading easyllm-0.0.1-py3-none-any.whl (4.3 kB)\n",
            "Collecting starlette==0.22.0 (from easyllm->-r requirements.txt (line 16))\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.22.0->easyllm->-r requirements.txt (line 16)) (3.7.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4))\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4)) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4))\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->easyllm->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->easyllm->-r requirements.txt (line 16)) (1.2.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.5.dev0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Building wheels for collected packages: transformers, accelerate, peft, trl\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8274566 sha256=3e3f4ee785e2744c0299e65185333f28b3b2eae81820b7e2cd74030640d159d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcf6yp0g/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.25.0.dev0-py3-none-any.whl size=269241 sha256=fff754c3f6e45253b7a08e1db6d76abbedffa629e7b8a639556b57ef15b2e5ad\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcf6yp0g/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.7.2.dev0-py3-none-any.whl size=169329 sha256=653c6ce4e01417c1b4ef73e82fc79fff842660f4602af1e317fb55629d360e82\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcf6yp0g/wheels/4c/16/67/1002a2d4daa822eff130e6d85b90051b75d2ce0d26b9448e4a\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trl: filename=trl-0.7.5.dev0-py3-none-any.whl size=139263 sha256=b350a0a5b3113d0130e8e159a77729ba1826ee28fddf5e63c43048fc52c50ac7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcf6yp0g/wheels/6a/aa/56/d64d9ae3521350622f9325fdc3bccb4dd3d3ec1c1d8e917400\n",
            "Successfully built transformers accelerate peft trl\n",
            "Installing collected packages: bitsandbytes, smmap, shtab, setproctitle, sentry-sdk, pyarrow-hotfix, einops, docstring-parser, docker-pycreds, dill, tiktoken, starlette, responses, multiprocess, gitdb, tyro, GitPython, easyllm, accelerate, wandb, transformers, datasets, trl, peft, evaluate\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.25.0.dev0 bitsandbytes-0.41.3.post2 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 docstring-parser-0.15 easyllm-0.0.1 einops-0.7.0 evaluate-0.4.1 gitdb-4.0.11 multiprocess-0.70.15 peft-0.7.2.dev0 pyarrow-hotfix-0.6 responses-0.18.0 sentry-sdk-1.39.1 setproctitle-1.3.3 shtab-1.6.5 smmap-5.0.1 starlette-0.22.0 tiktoken-0.5.2 transformers-4.37.0.dev0 trl-0.7.5.dev0 tyro-0.6.0 wandb-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDeOWLRT94_u",
        "outputId": "0c1bba85-db85-4ca7-d636-ad7b2c7b70df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.3.6.tar.gz (2.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.6-cp310-cp310-linux_x86_64.whl size=56477261 sha256=652ad256d0891cb2c6d7183f96f7f56ff61cdeee24388381abb35e7a0f2eeca1\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/5f/16/5044cdddb6dfb3331dfbffa28ab6096ec2900777af5cb0253a\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.3.6\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhFHDc9897L1",
        "outputId": "0879213b-183f-40e0-cffd-44590df4dc5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a8c5f6f32d174a3f8ed9a988209790c6",
            "3f4bb617f8f44df4a6b8e2c201b05e60",
            "bb0c02ed83bb42b6bd7f36c44aba4ff6",
            "d0bed69a0f934666b40792e92ea299ea",
            "05dc6e4a5a884dd7aeed1aeeb1e96e01",
            "bd05d3ae520e40bdbaf700f479c64319",
            "92a3492f4b66436db6c5e9f82366efbc",
            "02bfd07164d344b4be2294d5dd336b74",
            "eae8487ec51a4c518224e6f17740fbbf",
            "e39c4cbd8c1749638812f7f5db2a7e00",
            "9a476c82774e45e4a3eae83f251892c0",
            "80c88cda35fd44e6880ee4e8a13c1094",
            "05f0c5e504174a06af727faf58a93fa3",
            "e17dba515ea64bbb9772aad5e9da4c1b",
            "a3e5b1def1774f7295ae95a7a2fbfa3a",
            "c5e3db87cd144eb38ed7a17f65f42008",
            "0bf2b4eb227c440183eeffff156e514c",
            "dc87286ff9a84d3591e9fb2839dbcb92",
            "f289c7cbf6104263898142f100096e7e",
            "21e064d589604cf1bbd50261ae4fc260",
            "7e74fbf60a704f4d8bfa3c57b8b07d9a",
            "c3c68480413447b48d406e4cf451fe22",
            "2df13b1a0cc84e9cb6c11d073535f88a",
            "ff2cd3bac24d4e6d8ed5933250d51dfb",
            "0f6bb2f4480b4b1b94f7b4c5c6ab2b73",
            "0feb00156d404f70b066d30e2d6f260c",
            "0def82f031b0483890bed3d87a9f5609",
            "f5f81fd49ebf41e3b305abc4571a15ce",
            "d5f8186be8be462080e398683590d35f",
            "e36a07262bae422c9a4f2642504ea203",
            "dcb392d75a5c45ea9743955bbe1a18f0",
            "873504ef77dd47d2aa9f74c338ecfb2a"
          ]
        },
        "id": "7OYA9Kdd98lK",
        "outputId": "de191ec5-2892-492c-e6f9-0abc0456ec83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8c5f6f32d174a3f8ed9a988209790c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd chat_assistant/training/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqUUIIMg9_XC",
        "outputId": "70d727c3-9617-4879-ef47-9bbc97f614e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS-LLM-Workshop/chat_assistant/training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!WANDB_PROJECT=openhathi_instruct python train.py \\\n",
        "--seed 100 \\\n",
        "--model_name \"sarvamai/OpenHathi-7B-Hi-v0.1-Base\" \\\n",
        "--dataset_name \"smangrul/hindi_instruct_v1\" \\\n",
        "--chat_template_format \"chatml\" \\\n",
        "--add_special_tokens False \\\n",
        "--append_concat_token False \\\n",
        "--splits \"train,test\" \\\n",
        "--max_seq_len 2048 \\\n",
        "--num_train_epochs 3 \\\n",
        "--logging_steps 5 \\\n",
        "--log_level \"info\" \\\n",
        "--logging_strategy \"steps\" \\\n",
        "--evaluation_strategy \"epoch\" \\\n",
        "--save_strategy \"epoch\" \\\n",
        "--push_to_hub \\\n",
        "--hub_private_repo True \\\n",
        "--hub_strategy \"every_save\" \\\n",
        "--fp16 True \\\n",
        "--packing True \\\n",
        "--learning_rate 1e-4 \\\n",
        "--lr_scheduler_type \"cosine\" \\\n",
        "--weight_decay 1e-4 \\\n",
        "--warmup_ratio 0.03 \\\n",
        "--max_grad_norm 1.0 \\\n",
        "--output_dir \"OpenHathi-7B-Hi-v0.1-Instruct\" \\\n",
        "--per_device_train_batch_size 4 \\\n",
        "--per_device_eval_batch_size 4 \\\n",
        "--gradient_accumulation_steps 4 \\\n",
        "--gradient_checkpointing True \\\n",
        "--use_reentrant False \\\n",
        "--dataset_text_field \"content\" \\\n",
        "--use_peft_lora True \\\n",
        "--lora_r 8 \\\n",
        "--lora_alpha 16 \\\n",
        "--lora_dropout 0.1 \\\n",
        "--lora_target_modules \"q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj,embed_tokens,lm_head\" \\\n",
        "--use_4bit_qunatization True \\\n",
        "--use_nested_quant True \\\n",
        "--bnb_4bit_compute_dtype \"float16\" \\\n",
        "--gradient_checkpointing True \\\n",
        "--use_reentrant False \\\n",
        "--use_flash_attn True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WGBkP8o-CRO",
        "outputId": "6f83c248-4960-4248-e8ed-78f47061aa32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 312 bytes | 312.00 KiB/s, done.\n",
            "From https://github.com/pacman100/DHS-LLM-Workshop\n",
            "   91c25c5..6a5b3cf  main       -> origin/main\n",
            "Updating 91c25c5..6a5b3cf\n",
            "Fast-forward\n",
            " requirements.txt | 1 \u001b[32m+\u001b[m\n",
            " 1 file changed, 1 insertion(+)\n",
            "2023-12-22 05:07:54.247635: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-22 05:07:54.247691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-22 05:07:54.249427: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-22 05:07:55.396118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "================================================================================\n",
            "Your GPU supports bfloat16, you can accelerate training with the argument --bf16\n",
            "================================================================================\n",
            "config.json: 100% 667/667 [00:00<00:00, 3.85MB/s]\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 64.3MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 31.5M/4.98G [00:00<00:19, 252MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 62.9M/4.98G [00:00<00:20, 244MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 94.4M/4.98G [00:00<00:20, 243MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 136M/4.98G [00:00<00:17, 280MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.98G [00:00<00:14, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.98G [00:00<00:14, 320MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 262M/4.98G [00:00<00:16, 284MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 304M/4.98G [00:01<00:15, 302MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 336M/4.98G [00:01<00:15, 297MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 377M/4.98G [00:01<00:14, 312MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 419M/4.98G [00:01<00:15, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 451M/4.98G [00:01<00:14, 305MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 493M/4.98G [00:01<00:14, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 535M/4.98G [00:01<00:14, 310MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 577M/4.98G [00:01<00:13, 332MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 629M/4.98G [00:02<00:12, 355MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 671M/4.98G [00:02<00:12, 350MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 713M/4.98G [00:02<00:13, 314MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 755M/4.98G [00:02<00:14, 295MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 786M/4.98G [00:02<00:14, 286MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 818M/4.98G [00:02<00:14, 285MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 849M/4.98G [00:02<00:14, 290MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 881M/4.98G [00:02<00:14, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 912M/4.98G [00:03<00:14, 288MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 944M/4.98G [00:03<00:15, 266MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 975M/4.98G [00:03<00:15, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.02G/4.98G [00:03<00:14, 274MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.06G/4.98G [00:03<00:13, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.09G/4.98G [00:03<00:13, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.13G/4.98G [00:03<00:12, 301MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.16G/4.98G [00:03<00:12, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.98G [00:04<00:12, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.26G/4.98G [00:04<00:10, 344MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.30G/4.98G [00:04<00:10, 349MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.98G [00:04<00:10, 358MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.38G/4.98G [00:04<00:10, 343MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.44G/4.98G [00:04<00:10, 354MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.98G [00:04<00:10, 331MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.52G/4.98G [00:04<00:10, 337MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.56G/4.98G [00:05<00:10, 315MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.60G/4.98G [00:05<00:10, 313MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.65G/4.98G [00:05<00:10, 325MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.69G/4.98G [00:05<00:09, 336MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.73G/4.98G [00:05<00:09, 352MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.77G/4.98G [00:05<00:08, 369MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.81G/4.98G [00:05<00:09, 343MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.86G/4.98G [00:05<00:09, 334MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.91G/4.98G [00:06<00:08, 366MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.98G [00:06<00:08, 352MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.99G/4.98G [00:06<00:08, 356MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.03G/4.98G [00:06<00:08, 362MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.08G/4.98G [00:06<00:08, 356MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.12G/4.98G [00:06<00:09, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.16G/4.98G [00:06<00:09, 296MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.19G/4.98G [00:06<00:09, 285MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.23G/4.98G [00:07<00:09, 297MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.26G/4.98G [00:07<00:09, 296MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.30G/4.98G [00:07<00:09, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.34G/4.98G [00:07<00:08, 309MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.98G [00:07<00:08, 324MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.98G [00:07<00:07, 330MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.46G/4.98G [00:07<00:08, 313MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.51G/4.98G [00:07<00:07, 326MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.55G/4.98G [00:08<00:07, 317MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.98G [00:08<00:07, 315MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.98G [00:08<00:07, 317MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.67G/4.98G [00:08<00:06, 333MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.72G/4.98G [00:08<00:06, 338MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.76G/4.98G [00:08<00:06, 333MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.80G/4.98G [00:08<00:06, 340MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.84G/4.98G [00:08<00:06, 339MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.88G/4.98G [00:09<00:05, 356MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.98G [00:09<00:06, 328MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.97G/4.98G [00:09<00:06, 331MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 3.01G/4.98G [00:09<00:06, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.05G/4.98G [00:09<00:06, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.09G/4.98G [00:09<00:05, 340MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.14G/4.98G [00:09<00:05, 318MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.18G/4.98G [00:10<00:05, 327MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.22G/4.98G [00:10<00:05, 333MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.26G/4.98G [00:10<00:05, 339MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.30G/4.98G [00:10<00:04, 342MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.34G/4.98G [00:10<00:05, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.39G/4.98G [00:10<00:05, 292MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.98G [00:10<00:05, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.45G/4.98G [00:10<00:05, 296MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.50G/4.98G [00:11<00:04, 339MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.54G/4.98G [00:11<00:04, 355MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.59G/4.98G [00:11<00:03, 364MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.98G [00:11<00:04, 320MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.67G/4.98G [00:11<00:04, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.71G/4.98G [00:11<00:04, 314MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.75G/4.98G [00:11<00:03, 337MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.81G/4.98G [00:11<00:03, 366MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.85G/4.98G [00:12<00:03, 372MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.89G/4.98G [00:12<00:02, 376MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.93G/4.98G [00:12<00:02, 362MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.97G/4.98G [00:12<00:02, 373MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.02G/4.98G [00:12<00:02, 358MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.06G/4.98G [00:12<00:02, 357MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.10G/4.98G [00:12<00:02, 354MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.15G/4.98G [00:12<00:02, 376MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.19G/4.98G [00:12<00:02, 372MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.24G/4.98G [00:13<00:02, 336MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.28G/4.98G [00:13<00:01, 356MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.33G/4.98G [00:13<00:01, 366MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.37G/4.98G [00:13<00:01, 335MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.98G [00:13<00:01, 345MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.46G/4.98G [00:13<00:01, 331MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.50G/4.98G [00:13<00:01, 349MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.54G/4.98G [00:13<00:01, 339MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.58G/4.98G [00:14<00:01, 353MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.62G/4.98G [00:14<00:00, 366MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.67G/4.98G [00:14<00:00, 351MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.71G/4.98G [00:14<00:00, 364MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.75G/4.98G [00:14<00:00, 360MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.80G/4.98G [00:14<00:00, 385MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.84G/4.98G [00:14<00:00, 351MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.89G/4.98G [00:14<00:00, 359MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.93G/4.98G [00:15<00:00, 348MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.98G/4.98G [00:15<00:00, 328MB/s]\n",
            "Downloading shards:  33% 1/3 [00:15<00:31, 15.82s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 31.5M/4.95G [00:00<00:16, 298MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 62.9M/4.95G [00:00<00:18, 262MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 105M/4.95G [00:00<00:16, 293MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 136M/4.95G [00:00<00:25, 185MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 178M/4.95G [00:00<00:20, 233MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 231M/4.95G [00:00<00:16, 288MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 273M/4.95G [00:00<00:15, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 315M/4.95G [00:01<00:14, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 357M/4.95G [00:01<00:14, 319MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 398M/4.95G [00:01<00:13, 335MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 440M/4.95G [00:01<00:14, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 482M/4.95G [00:01<00:14, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 514M/4.95G [00:01<00:15, 282MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 545M/4.95G [00:01<00:17, 257MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 577M/4.95G [00:02<00:16, 261MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 619M/4.95G [00:02<00:15, 280MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 650M/4.95G [00:02<00:15, 277MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 692M/4.95G [00:02<00:14, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 734M/4.95G [00:02<00:13, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 765M/4.95G [00:02<00:14, 293MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 797M/4.95G [00:02<00:14, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 839M/4.95G [00:02<00:12, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 881M/4.95G [00:03<00:13, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 923M/4.95G [00:03<00:12, 322MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 965M/4.95G [00:03<00:11, 338MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.01G/4.95G [00:03<00:11, 354MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.05G/4.95G [00:03<00:10, 356MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.09G/4.95G [00:03<00:10, 353MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.13G/4.95G [00:03<00:10, 352MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.17G/4.95G [00:03<00:10, 357MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.22G/4.95G [00:03<00:10, 353MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.26G/4.95G [00:04<00:11, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.30G/4.95G [00:04<00:11, 313MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/4.95G [00:04<00:12, 293MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.37G/4.95G [00:04<00:12, 286MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.41G/4.95G [00:04<00:12, 280MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.44G/4.95G [00:04<00:14, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.47G/4.95G [00:05<00:15, 223MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.50G/4.95G [00:05<00:14, 234MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/4.95G [00:05<00:13, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.56G/4.95G [00:05<00:13, 258MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/4.95G [00:05<00:12, 260MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.64G/4.95G [00:05<00:11, 291MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.68G/4.95G [00:05<00:10, 306MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.71G/4.95G [00:05<00:10, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.75G/4.95G [00:05<00:10, 316MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.79G/4.95G [00:06<00:09, 339MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.84G/4.95G [00:06<00:08, 349MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.88G/4.95G [00:06<00:09, 322MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.92G/4.95G [00:06<00:09, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.96G/4.95G [00:06<00:09, 320MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 2.00G/4.95G [00:06<00:08, 334MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.04G/4.95G [00:06<00:09, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.09G/4.95G [00:06<00:09, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.13G/4.95G [00:07<00:09, 307MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.17G/4.95G [00:07<00:08, 320MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.21G/4.95G [00:07<00:08, 337MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.25G/4.95G [00:07<00:08, 330MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.30G/4.95G [00:07<00:08, 326MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.34G/4.95G [00:07<00:08, 307MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.37G/4.95G [00:07<00:09, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.41G/4.95G [00:08<00:08, 308MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.44G/4.95G [00:08<00:08, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.49G/4.95G [00:08<00:08, 306MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.53G/4.95G [00:08<00:07, 329MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.57G/4.95G [00:08<00:07, 325MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.61G/4.95G [00:08<00:08, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/4.95G [00:08<00:08, 279MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.68G/4.95G [00:08<00:07, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.73G/4.95G [00:09<00:07, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.77G/4.95G [00:09<00:07, 277MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.81G/4.95G [00:09<00:07, 287MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.85G/4.95G [00:09<00:06, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/4.95G [00:09<00:06, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.94G/4.95G [00:09<00:06, 321MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.98G/4.95G [00:09<00:05, 345MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.02G/4.95G [00:10<00:05, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.06G/4.95G [00:10<00:07, 245MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.09G/4.95G [00:10<00:07, 257MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.12G/4.95G [00:10<00:06, 266MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.17G/4.95G [00:10<00:06, 281MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.21G/4.95G [00:10<00:05, 303MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.25G/4.95G [00:10<00:05, 297MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.29G/4.95G [00:10<00:05, 312MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.33G/4.95G [00:11<00:05, 318MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.38G/4.95G [00:11<00:04, 322MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.42G/4.95G [00:11<00:04, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.46G/4.95G [00:11<00:04, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.50G/4.95G [00:11<00:05, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.53G/4.95G [00:11<00:04, 293MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.58G/4.95G [00:11<00:04, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.62G/4.95G [00:12<00:04, 316MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.66G/4.95G [00:12<00:04, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.70G/4.95G [00:12<00:03, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.74G/4.95G [00:12<00:03, 328MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.79G/4.95G [00:12<00:03, 333MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/4.95G [00:12<00:03, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.87G/4.95G [00:12<00:03, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.91G/4.95G [00:12<00:03, 320MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.95G/4.95G [00:13<00:03, 322MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.00G/4.95G [00:13<00:02, 343MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.04G/4.95G [00:13<00:02, 349MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.08G/4.95G [00:13<00:02, 352MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.12G/4.95G [00:13<00:02, 336MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.16G/4.95G [00:13<00:02, 346MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.20G/4.95G [00:13<00:02, 341MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.25G/4.95G [00:14<00:02, 286MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.28G/4.95G [00:14<00:02, 288MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.32G/4.95G [00:14<00:02, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.36G/4.95G [00:14<00:02, 282MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.40G/4.95G [00:14<00:01, 287MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.44G/4.95G [00:14<00:02, 246MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.47G/4.95G [00:14<00:02, 236MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.50G/4.95G [00:14<00:01, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.54G/4.95G [00:15<00:01, 265MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.57G/4.95G [00:15<00:01, 272MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.61G/4.95G [00:15<00:01, 297MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.66G/4.95G [00:15<00:00, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.70G/4.95G [00:15<00:00, 334MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.74G/4.95G [00:15<00:00, 348MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.78G/4.95G [00:15<00:00, 343MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.82G/4.95G [00:15<00:00, 337MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.87G/4.95G [00:16<00:00, 347MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.91G/4.95G [00:16<00:00, 348MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.95G/4.95G [00:16<00:00, 303MB/s]\n",
            "Downloading shards:  67% 2/3 [00:32<00:16, 16.41s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/3.81G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 31.5M/3.81G [00:00<00:14, 269MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 73.4M/3.81G [00:00<00:11, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   3% 105M/3.81G [00:00<00:13, 276MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 136M/3.81G [00:00<00:12, 283MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   5% 178M/3.81G [00:00<00:11, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 210M/3.81G [00:00<00:12, 296MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 241M/3.81G [00:00<00:12, 287MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   7% 283M/3.81G [00:00<00:11, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 315M/3.81G [00:01<00:11, 300MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   9% 346M/3.81G [00:01<00:11, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 377M/3.81G [00:01<00:11, 287MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  11% 409M/3.81G [00:01<00:12, 275MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 440M/3.81G [00:01<00:12, 269MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 472M/3.81G [00:01<00:12, 263MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 514M/3.81G [00:01<00:11, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  14% 545M/3.81G [00:01<00:11, 282MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 577M/3.81G [00:02<00:12, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 608M/3.81G [00:02<00:11, 274MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  17% 650M/3.81G [00:02<00:10, 292MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 692M/3.81G [00:02<00:09, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 734M/3.81G [00:02<00:09, 327MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  20% 776M/3.81G [00:02<00:09, 317MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 828M/3.81G [00:02<00:08, 358MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 870M/3.81G [00:02<00:07, 373MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 912M/3.81G [00:03<00:08, 344MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 954M/3.81G [00:03<00:08, 325MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 996M/3.81G [00:03<00:08, 326MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 1.04G/3.81G [00:03<00:11, 233MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  29% 1.09G/3.81G [00:03<00:09, 275MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.13G/3.81G [00:03<00:09, 294MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 1.17G/3.81G [00:03<00:08, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 1.22G/3.81G [00:04<00:08, 304MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 1.26G/3.81G [00:04<00:08, 297MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.29G/3.81G [00:04<00:09, 279MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 1.32G/3.81G [00:04<00:09, 251MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 1.35G/3.81G [00:04<00:09, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 1.38G/3.81G [00:04<00:09, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 1.43G/3.81G [00:04<00:08, 280MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  39% 1.47G/3.81G [00:04<00:07, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 1.51G/3.81G [00:05<00:07, 327MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 1.55G/3.81G [00:05<00:06, 341MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 1.59G/3.81G [00:05<00:06, 352MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  43% 1.64G/3.81G [00:05<00:06, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 1.68G/3.81G [00:05<00:06, 317MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 1.72G/3.81G [00:05<00:06, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 1.76G/3.81G [00:05<00:06, 317MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 1.80G/3.81G [00:06<00:06, 310MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 1.85G/3.81G [00:06<00:06, 309MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 1.88G/3.81G [00:06<00:06, 292MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 1.92G/3.81G [00:06<00:06, 315MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 1.96G/3.81G [00:06<00:05, 331MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 2.00G/3.81G [00:06<00:05, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 2.06G/3.81G [00:06<00:04, 366MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 2.10G/3.81G [00:06<00:04, 344MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 2.14G/3.81G [00:07<00:04, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  57% 2.18G/3.81G [00:07<00:04, 355MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 2.22G/3.81G [00:07<00:04, 349MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.26G/3.81G [00:07<00:04, 336MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 2.31G/3.81G [00:07<00:04, 335MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.35G/3.81G [00:07<00:04, 336MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 2.39G/3.81G [00:07<00:04, 339MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 2.43G/3.81G [00:07<00:04, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 2.47G/3.81G [00:08<00:04, 295MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 2.52G/3.81G [00:08<00:04, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 2.56G/3.81G [00:08<00:03, 315MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 2.60G/3.81G [00:08<00:03, 330MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 2.65G/3.81G [00:08<00:03, 358MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 2.69G/3.81G [00:08<00:03, 362MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 2.74G/3.81G [00:08<00:02, 362MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 2.78G/3.81G [00:08<00:02, 369MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 2.82G/3.81G [00:09<00:02, 351MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 2.86G/3.81G [00:09<00:02, 355MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  76% 2.90G/3.81G [00:09<00:02, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 2.95G/3.81G [00:09<00:02, 351MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 2.99G/3.81G [00:09<00:02, 343MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 3.03G/3.81G [00:09<00:02, 344MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.07G/3.81G [00:09<00:02, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  82% 3.11G/3.81G [00:09<00:02, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 3.16G/3.81G [00:10<00:02, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 3.20G/3.81G [00:10<00:02, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 3.24G/3.81G [00:10<00:01, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 3.28G/3.81G [00:10<00:01, 333MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  87% 3.32G/3.81G [00:10<00:01, 318MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 3.37G/3.81G [00:10<00:01, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 3.41G/3.81G [00:10<00:01, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 3.45G/3.81G [00:11<00:01, 286MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  91% 3.48G/3.81G [00:11<00:01, 232MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 3.51G/3.81G [00:11<00:01, 247MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 3.55G/3.81G [00:11<00:00, 271MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  94% 3.59G/3.81G [00:11<00:00, 236MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 3.63G/3.81G [00:11<00:00, 251MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 3.67G/3.81G [00:11<00:00, 267MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 3.71G/3.81G [00:12<00:00, 284MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 3.74G/3.81G [00:12<00:00, 270MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 3.81G/3.81G [00:12<00:00, 308MB/s]\n",
            "Downloading shards: 100% 3/3 [00:45<00:00, 15.19s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:07<00:00,  2.45s/it]\n",
            "generation_config.json: 100% 184/184 [00:00<00:00, 930kB/s]\n",
            "tokenizer_config.json: 100% 936/936 [00:00<00:00, 5.21MB/s]\n",
            "tokenizer.model: 100% 968k/968k [00:00<00:00, 204MB/s]\n",
            "tokenizer.json: 100% 2.85M/2.85M [00:01<00:00, 2.01MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.69MB/s]\n",
            "Downloading readme: 100% 30.1k/30.1k [00:00<00:00, 55.7MB/s]\n",
            "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/13.4M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  31% 4.19M/13.4M [00:00<00:01, 6.96MB/s]\u001b[A\n",
            "Downloading data: 100% 13.4M/13.4M [00:01<00:00, 11.4MB/s]\n",
            "Downloading data files:  50% 1/2 [00:01<00:01,  1.17s/it]\n",
            "Downloading data:   0% 0.00/1.30M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100% 1.30M/1.30M [00:00<00:00, 2.21MB/s]\n",
            "Downloading data files: 100% 2/2 [00:01<00:00,  1.14it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1793.97it/s]\n",
            "Generating train split: 100% 20230/20230 [00:00<00:00, 107629.06 examples/s]\n",
            "Generating test split: 100% 7788/7788 [00:00<00:00, 610040.70 examples/s]\n",
            "Map: 100% 20230/20230 [00:01<00:00, 16694.19 examples/s]\n",
            "Map: 100% 7788/7788 [00:00<00:00, 20967.05 examples/s]\n",
            "Size of the train set: 20230. Size of the validation set: 7788\n",
            "A sample of train dataset: {'content': '<|im_start|>user\\nमुझे अपनी ऑनलाइन साइट के लिए एक विवरण चाहिए जो उन कपड़ों का वर्णन करता है जिन्हें मैं बेचने की कोशिश कर रहा हूं। वे प्रवाहित और एक तरह से जादुई हैं। 3 रंग हैंः हल्का नीला, गुलाबी और सफेद। पोशाक घुटने के ठीक ऊपर से टकराती है और इसमें छोटी बाजू होती है। मुझे कुछ ऐसा चाहिए जो वास्तव में इस उत्पाद को बेचने में मेरी मदद करे। अन्य जानकारी यह है कि इसका आकार xs से x-बड़ा होता है। इसे कुछ वाक्यों तक रखने की कोशिश करें (<5 अधिमानतः)।<|im_end|>\\n<|im_start|>assistant\\nएक ऐसी बहती पोशाक की तलाश है जो आपको हल्का और हवादार महसूस कराए? आगे नहीं देखें तीन स्वप्निल रंगों में से चुनने के लिए, सभी के लिए कुछ न कुछ है। यह पोशाक घुटने के ठीक ऊपर से टकराती है और एक जादुई प्रभाव पैदा करने के लिए आपके चारों ओर तैरती है जिसे हर कोई पसंद करेगा। आकारों में अतिरिक्त छोटे से लेकर अतिरिक्त बड़े शामिल हैं।<|im_end|>\\n'}\n",
            "Generating train split: 2546 examples [00:04, 560.08 examples/s]\n",
            "Generating train split: 335 examples [00:00, 564.54 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:282: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n",
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): lora.Embedding(\n",
            "          (base_layer): Embedding(48072, 4096)\n",
            "          (lora_dropout): ModuleDict(\n",
            "            (default): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (lora_A): ModuleDict()\n",
            "          (lora_B): ModuleDict()\n",
            "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 8x48072 (cuda:0)])\n",
            "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 4096x8 (cuda:0)])\n",
            "        )\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaFlashAttention2(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (rotary_emb): LlamaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=11008, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=11008, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm()\n",
            "            (post_attention_layernorm): LlamaRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=4096, out_features=48072, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=8, out_features=48072, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "trainable params: 20,823,168 || all params: 6,890,900,608 || trainable%: 0.3021835487777217\n",
            "***** Running training *****\n",
            "  Num examples = 2,546\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 477\n",
            "  Number of trainable parameters = 20,823,168\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmangrul\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/DHS-LLM-Workshop/chat_assistant/training/wandb/run-20231222_050918-gde27ixu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvaliant-donkey-4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/smangrul/openhathi_instruct\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/smangrul/openhathi_instruct/runs/gde27ixu\u001b[0m\n",
            "  0% 0/477 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n",
            "{'loss': 2.7362, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
            "{'loss': 2.6718, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 2.5898, 'learning_rate': 0.0001, 'epoch': 0.09}\n",
            "{'loss': 2.3973, 'learning_rate': 9.997110291906109e-05, 'epoch': 0.13}\n",
            "{'loss': 2.2989, 'learning_rate': 9.988444507789582e-05, 'epoch': 0.16}\n",
            "{'loss': 2.1682, 'learning_rate': 9.974012664285021e-05, 'epoch': 0.19}\n",
            "{'loss': 2.098, 'learning_rate': 9.953831442918418e-05, 'epoch': 0.22}\n",
            "{'loss': 2.0109, 'learning_rate': 9.933562366956445e-05, 'epoch': 0.25}\n",
            "{'loss': 2.0076, 'learning_rate': 9.903095498651275e-05, 'epoch': 0.28}\n",
            "{'loss': 1.9032, 'learning_rate': 9.866961224447075e-05, 'epoch': 0.31}\n",
            "{'loss': 1.9476, 'learning_rate': 9.8252013113457e-05, 'epoch': 0.35}\n",
            "{'loss': 1.9022, 'learning_rate': 9.777864028930705e-05, 'epoch': 0.38}\n",
            "{'loss': 1.8249, 'learning_rate': 9.725004093573342e-05, 'epoch': 0.41}\n",
            "{'loss': 1.797, 'learning_rate': 9.666682605186835e-05, 'epoch': 0.44}\n",
            "{'loss': 1.8358, 'learning_rate': 9.602966976601993e-05, 'epoch': 0.47}\n",
            "{'loss': 1.8271, 'learning_rate': 9.533930855645872e-05, 'epoch': 0.5}\n",
            "{'loss': 1.8118, 'learning_rate': 9.45965404001347e-05, 'epoch': 0.53}\n",
            "{'loss': 1.7487, 'learning_rate': 9.380222385030915e-05, 'epoch': 0.57}\n",
            "{'loss': 1.7736, 'learning_rate': 9.295727704416731e-05, 'epoch': 0.6}\n",
            "{'loss': 1.7495, 'learning_rate': 9.206267664155907e-05, 'epoch': 0.63}\n",
            "{'loss': 1.7458, 'learning_rate': 9.111945669609408e-05, 'epoch': 0.66}\n",
            "{'loss': 1.7187, 'learning_rate': 9.012870745989663e-05, 'epoch': 0.69}\n",
            "{'loss': 1.6566, 'learning_rate': 8.90915741234015e-05, 'epoch': 0.72}\n",
            "{'loss': 1.7181, 'learning_rate': 8.800925549164741e-05, 'epoch': 0.75}\n",
            "{'loss': 1.6605, 'learning_rate': 8.688300259859854e-05, 'epoch': 0.78}\n",
            "{'loss': 1.7084, 'learning_rate': 8.571411726109519e-05, 'epoch': 0.82}\n",
            "{'loss': 1.6627, 'learning_rate': 8.450395057410561e-05, 'epoch': 0.85}\n",
            "{'loss': 1.7245, 'learning_rate': 8.325390134901794e-05, 'epoch': 0.88}\n",
            "{'loss': 1.691, 'learning_rate': 8.196541449677758e-05, 'epoch': 0.91}\n",
            "{'loss': 1.6995, 'learning_rate': 8.063997935773885e-05, 'epoch': 0.94}\n",
            "{'loss': 1.7258, 'learning_rate': 7.927912798016143e-05, 'epoch': 0.97}\n",
            " 33% 159/477 [38:51<1:17:39, 14.65s/it]***** Running Evaluation *****\n",
            "  Num examples = 335\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/84 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/84 [00:01<00:45,  1.80it/s]\u001b[A\n",
            "  4% 3/84 [00:02<01:03,  1.27it/s]\u001b[A\n",
            "  5% 4/84 [00:03<01:12,  1.10it/s]\u001b[A\n",
            "  6% 5/84 [00:04<01:17,  1.02it/s]\u001b[A\n",
            "  7% 6/84 [00:05<01:19,  1.03s/it]\u001b[A\n",
            "  8% 7/84 [00:06<01:21,  1.05s/it]\u001b[A\n",
            " 10% 8/84 [00:07<01:21,  1.07s/it]\u001b[A\n",
            " 11% 9/84 [00:08<01:21,  1.09s/it]\u001b[A\n",
            " 12% 10/84 [00:10<01:20,  1.09s/it]\u001b[A\n",
            " 13% 11/84 [00:11<01:20,  1.10s/it]\u001b[A\n",
            " 14% 12/84 [00:12<01:19,  1.10s/it]\u001b[A\n",
            " 15% 13/84 [00:13<01:18,  1.11s/it]\u001b[A\n",
            " 17% 14/84 [00:14<01:17,  1.11s/it]\u001b[A\n",
            " 18% 15/84 [00:15<01:16,  1.11s/it]\u001b[A\n",
            " 19% 16/84 [00:16<01:15,  1.11s/it]\u001b[A\n",
            " 20% 17/84 [00:17<01:14,  1.11s/it]\u001b[A\n",
            " 21% 18/84 [00:18<01:13,  1.11s/it]\u001b[A\n",
            " 23% 19/84 [00:20<01:12,  1.11s/it]\u001b[A\n",
            " 24% 20/84 [00:21<01:11,  1.11s/it]\u001b[A\n",
            " 25% 21/84 [00:22<01:10,  1.11s/it]\u001b[A\n",
            " 26% 22/84 [00:23<01:09,  1.11s/it]\u001b[A\n",
            " 27% 23/84 [00:24<01:07,  1.11s/it]\u001b[A\n",
            " 29% 24/84 [00:25<01:06,  1.11s/it]\u001b[A\n",
            " 30% 25/84 [00:26<01:05,  1.11s/it]\u001b[A\n",
            " 31% 26/84 [00:27<01:04,  1.11s/it]\u001b[A\n",
            " 32% 27/84 [00:28<01:03,  1.11s/it]\u001b[A\n",
            " 33% 28/84 [00:30<01:02,  1.11s/it]\u001b[A\n",
            " 35% 29/84 [00:31<01:01,  1.12s/it]\u001b[A\n",
            " 36% 30/84 [00:32<01:00,  1.12s/it]\u001b[A\n",
            " 37% 31/84 [00:33<00:59,  1.12s/it]\u001b[A\n",
            " 38% 32/84 [00:34<00:57,  1.12s/it]\u001b[A\n",
            " 39% 33/84 [00:35<00:56,  1.11s/it]\u001b[A\n",
            " 40% 34/84 [00:36<00:55,  1.11s/it]\u001b[A\n",
            " 42% 35/84 [00:37<00:54,  1.11s/it]\u001b[A\n",
            " 43% 36/84 [00:39<00:53,  1.11s/it]\u001b[A\n",
            " 44% 37/84 [00:40<00:52,  1.12s/it]\u001b[A\n",
            " 45% 38/84 [00:41<00:51,  1.12s/it]\u001b[A\n",
            " 46% 39/84 [00:42<00:50,  1.12s/it]\u001b[A\n",
            " 48% 40/84 [00:43<00:49,  1.12s/it]\u001b[A\n",
            " 49% 41/84 [00:44<00:47,  1.12s/it]\u001b[A\n",
            " 50% 42/84 [00:45<00:46,  1.12s/it]\u001b[A\n",
            " 51% 43/84 [00:46<00:45,  1.12s/it]\u001b[A\n",
            " 52% 44/84 [00:47<00:44,  1.12s/it]\u001b[A\n",
            " 54% 45/84 [00:49<00:43,  1.12s/it]\u001b[A\n",
            " 55% 46/84 [00:50<00:42,  1.12s/it]\u001b[A\n",
            " 56% 47/84 [00:51<00:41,  1.11s/it]\u001b[A\n",
            " 57% 48/84 [00:52<00:40,  1.11s/it]\u001b[A\n",
            " 58% 49/84 [00:53<00:38,  1.11s/it]\u001b[A\n",
            " 60% 50/84 [00:54<00:37,  1.11s/it]\u001b[A\n",
            " 61% 51/84 [00:55<00:36,  1.11s/it]\u001b[A\n",
            " 62% 52/84 [00:56<00:35,  1.12s/it]\u001b[A\n",
            " 63% 53/84 [00:57<00:34,  1.12s/it]\u001b[A\n",
            " 64% 54/84 [00:59<00:33,  1.12s/it]\u001b[A\n",
            " 65% 55/84 [01:00<00:32,  1.12s/it]\u001b[A\n",
            " 67% 56/84 [01:01<00:31,  1.12s/it]\u001b[A\n",
            " 68% 57/84 [01:02<00:30,  1.12s/it]\u001b[A\n",
            " 69% 58/84 [01:03<00:29,  1.12s/it]\u001b[A\n",
            " 70% 59/84 [01:04<00:27,  1.12s/it]\u001b[A\n",
            " 71% 60/84 [01:05<00:26,  1.12s/it]\u001b[A\n",
            " 73% 61/84 [01:06<00:25,  1.12s/it]\u001b[A\n",
            " 74% 62/84 [01:08<00:24,  1.12s/it]\u001b[A\n",
            " 75% 63/84 [01:09<00:23,  1.12s/it]\u001b[A\n",
            " 76% 64/84 [01:10<00:22,  1.11s/it]\u001b[A\n",
            " 77% 65/84 [01:11<00:21,  1.12s/it]\u001b[A\n",
            " 79% 66/84 [01:12<00:20,  1.12s/it]\u001b[A\n",
            " 80% 67/84 [01:13<00:18,  1.12s/it]\u001b[A\n",
            " 81% 68/84 [01:14<00:17,  1.12s/it]\u001b[A\n",
            " 82% 69/84 [01:15<00:16,  1.11s/it]\u001b[A\n",
            " 83% 70/84 [01:16<00:15,  1.11s/it]\u001b[A\n",
            " 85% 71/84 [01:18<00:14,  1.11s/it]\u001b[A\n",
            " 86% 72/84 [01:19<00:13,  1.11s/it]\u001b[A\n",
            " 87% 73/84 [01:20<00:12,  1.12s/it]\u001b[A\n",
            " 88% 74/84 [01:21<00:11,  1.12s/it]\u001b[A\n",
            " 89% 75/84 [01:22<00:10,  1.12s/it]\u001b[A\n",
            " 90% 76/84 [01:23<00:08,  1.12s/it]\u001b[A\n",
            " 92% 77/84 [01:24<00:07,  1.12s/it]\u001b[A\n",
            " 93% 78/84 [01:25<00:06,  1.12s/it]\u001b[A\n",
            " 94% 79/84 [01:26<00:05,  1.12s/it]\u001b[A\n",
            " 95% 80/84 [01:28<00:04,  1.12s/it]\u001b[A\n",
            " 96% 81/84 [01:29<00:03,  1.11s/it]\u001b[A\n",
            " 98% 82/84 [01:30<00:02,  1.11s/it]\u001b[A\n",
            " 99% 83/84 [01:31<00:01,  1.11s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2686867713928223, 'eval_runtime': 93.4333, 'eval_samples_per_second': 3.585, 'eval_steps_per_second': 0.899, 'epoch': 1.0}\n",
            " 33% 159/477 [40:26<1:17:39, 14.65s/it]\n",
            "100% 84/84 [01:32<00:00,  1.06s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-159\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-159/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-159/special_tokens_map.json\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/special_tokens_map.json\n",
            "{'loss': 1.6621, 'learning_rate': 7.788443334934148e-05, 'epoch': 1.0}\n",
            "{'loss': 1.642, 'learning_rate': 7.645750756942425e-05, 'epoch': 1.04}\n",
            "{'loss': 1.6387, 'learning_rate': 7.500000000000001e-05, 'epoch': 1.07}\n",
            "{'loss': 1.6138, 'learning_rate': 7.351359534963684e-05, 'epoch': 1.1}\n",
            "{'loss': 1.6264, 'learning_rate': 7.200001172855435e-05, 'epoch': 1.13}\n",
            "{'loss': 1.6181, 'learning_rate': 7.046099866268879e-05, 'epoch': 1.16}\n",
            "{'loss': 1.5979, 'learning_rate': 6.889833507144532e-05, 'epoch': 1.19}\n",
            "{'loss': 1.6432, 'learning_rate': 6.731382721147508e-05, 'epoch': 1.22}\n",
            "{'loss': 1.6097, 'learning_rate': 6.570930658885313e-05, 'epoch': 1.26}\n",
            "{'loss': 1.6447, 'learning_rate': 6.408662784207149e-05, 'epoch': 1.29}\n",
            "{'loss': 1.6339, 'learning_rate': 6.244766659829351e-05, 'epoch': 1.32}\n",
            "{'loss': 1.5858, 'learning_rate': 6.079431730534786e-05, 'epoch': 1.35}\n",
            "{'loss': 1.6194, 'learning_rate': 5.9128491041968094e-05, 'epoch': 1.38}\n",
            "{'loss': 1.6423, 'learning_rate': 5.745211330880872e-05, 'epoch': 1.41}\n",
            "{'loss': 1.6613, 'learning_rate': 5.576712180279133e-05, 'epoch': 1.44}\n",
            "{'loss': 1.6035, 'learning_rate': 5.4075464177353164e-05, 'epoch': 1.48}\n",
            "{'loss': 1.6248, 'learning_rate': 5.2379095791187124e-05, 'epoch': 1.51}\n",
            "{'loss': 1.6227, 'learning_rate': 5.06799774480755e-05, 'epoch': 1.54}\n",
            "{'loss': 1.6001, 'learning_rate': 4.9320022551924516e-05, 'epoch': 1.57}\n",
            "{'loss': 1.5992, 'learning_rate': 4.762090420881289e-05, 'epoch': 1.6}\n",
            "{'loss': 1.6324, 'learning_rate': 4.592453582264684e-05, 'epoch': 1.63}\n",
            "{'loss': 1.6463, 'learning_rate': 4.423287819720866e-05, 'epoch': 1.66}\n",
            "{'loss': 1.62, 'learning_rate': 4.254788669119127e-05, 'epoch': 1.7}\n",
            "{'loss': 1.633, 'learning_rate': 4.0871508958031924e-05, 'epoch': 1.73}\n",
            "{'loss': 1.6062, 'learning_rate': 3.9205682694652154e-05, 'epoch': 1.76}\n",
            "{'loss': 1.6505, 'learning_rate': 3.755233340170651e-05, 'epoch': 1.79}\n",
            "{'loss': 1.6333, 'learning_rate': 3.591337215792852e-05, 'epoch': 1.82}\n",
            "{'loss': 1.6185, 'learning_rate': 3.429069341114688e-05, 'epoch': 1.85}\n",
            "{'loss': 1.5779, 'learning_rate': 3.2686172788524935e-05, 'epoch': 1.88}\n",
            "{'loss': 1.6139, 'learning_rate': 3.110166492855468e-05, 'epoch': 1.92}\n",
            "{'loss': 1.6004, 'learning_rate': 2.9539001337311233e-05, 'epoch': 1.95}\n",
            "{'loss': 1.5829, 'learning_rate': 2.7999988271445643e-05, 'epoch': 1.98}\n",
            " 67% 318/477 [1:19:22<38:49, 14.65s/it]***** Running Evaluation *****\n",
            "  Num examples = 335\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/84 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/84 [00:01<00:45,  1.79it/s]\u001b[A\n",
            "  4% 3/84 [00:02<01:03,  1.27it/s]\u001b[A\n",
            "  5% 4/84 [00:03<01:12,  1.10it/s]\u001b[A\n",
            "  6% 5/84 [00:04<01:17,  1.02it/s]\u001b[A\n",
            "  7% 6/84 [00:05<01:20,  1.03s/it]\u001b[A\n",
            "  8% 7/84 [00:06<01:21,  1.05s/it]\u001b[A\n",
            " 10% 8/84 [00:07<01:21,  1.07s/it]\u001b[A\n",
            " 11% 9/84 [00:08<01:21,  1.09s/it]\u001b[A\n",
            " 12% 10/84 [00:10<01:20,  1.09s/it]\u001b[A\n",
            " 13% 11/84 [00:11<01:20,  1.10s/it]\u001b[A\n",
            " 14% 12/84 [00:12<01:19,  1.11s/it]\u001b[A\n",
            " 15% 13/84 [00:13<01:18,  1.11s/it]\u001b[A\n",
            " 17% 14/84 [00:14<01:17,  1.11s/it]\u001b[A\n",
            " 18% 15/84 [00:15<01:16,  1.11s/it]\u001b[A\n",
            " 19% 16/84 [00:16<01:15,  1.11s/it]\u001b[A\n",
            " 20% 17/84 [00:17<01:14,  1.11s/it]\u001b[A\n",
            " 21% 18/84 [00:18<01:13,  1.11s/it]\u001b[A\n",
            " 23% 19/84 [00:20<01:12,  1.11s/it]\u001b[A\n",
            " 24% 20/84 [00:21<01:11,  1.12s/it]\u001b[A\n",
            " 25% 21/84 [00:22<01:10,  1.11s/it]\u001b[A\n",
            " 26% 22/84 [00:23<01:09,  1.11s/it]\u001b[A\n",
            " 27% 23/84 [00:24<01:08,  1.11s/it]\u001b[A\n",
            " 29% 24/84 [00:25<01:06,  1.11s/it]\u001b[A\n",
            " 30% 25/84 [00:26<01:05,  1.11s/it]\u001b[A\n",
            " 31% 26/84 [00:27<01:04,  1.11s/it]\u001b[A\n",
            " 32% 27/84 [00:28<01:03,  1.11s/it]\u001b[A\n",
            " 33% 28/84 [00:30<01:02,  1.11s/it]\u001b[A\n",
            " 35% 29/84 [00:31<01:01,  1.12s/it]\u001b[A\n",
            " 36% 30/84 [00:32<01:00,  1.12s/it]\u001b[A\n",
            " 37% 31/84 [00:33<00:59,  1.12s/it]\u001b[A\n",
            " 38% 32/84 [00:34<00:57,  1.12s/it]\u001b[A\n",
            " 39% 33/84 [00:35<00:56,  1.12s/it]\u001b[A\n",
            " 40% 34/84 [00:36<00:55,  1.12s/it]\u001b[A\n",
            " 42% 35/84 [00:37<00:54,  1.12s/it]\u001b[A\n",
            " 43% 36/84 [00:39<00:53,  1.12s/it]\u001b[A\n",
            " 44% 37/84 [00:40<00:52,  1.12s/it]\u001b[A\n",
            " 45% 38/84 [00:41<00:51,  1.12s/it]\u001b[A\n",
            " 46% 39/84 [00:42<00:50,  1.12s/it]\u001b[A\n",
            " 48% 40/84 [00:43<00:49,  1.12s/it]\u001b[A\n",
            " 49% 41/84 [00:44<00:47,  1.12s/it]\u001b[A\n",
            " 50% 42/84 [00:45<00:46,  1.12s/it]\u001b[A\n",
            " 51% 43/84 [00:46<00:45,  1.12s/it]\u001b[A\n",
            " 52% 44/84 [00:47<00:44,  1.12s/it]\u001b[A\n",
            " 54% 45/84 [00:49<00:43,  1.12s/it]\u001b[A\n",
            " 55% 46/84 [00:50<00:42,  1.12s/it]\u001b[A\n",
            " 56% 47/84 [00:51<00:41,  1.12s/it]\u001b[A\n",
            " 57% 48/84 [00:52<00:40,  1.12s/it]\u001b[A\n",
            " 58% 49/84 [00:53<00:39,  1.11s/it]\u001b[A\n",
            " 60% 50/84 [00:54<00:37,  1.11s/it]\u001b[A\n",
            " 61% 51/84 [00:55<00:36,  1.11s/it]\u001b[A\n",
            " 62% 52/84 [00:56<00:35,  1.12s/it]\u001b[A\n",
            " 63% 53/84 [00:57<00:34,  1.11s/it]\u001b[A\n",
            " 64% 54/84 [00:59<00:33,  1.11s/it]\u001b[A\n",
            " 65% 55/84 [01:00<00:32,  1.11s/it]\u001b[A\n",
            " 67% 56/84 [01:01<00:31,  1.11s/it]\u001b[A\n",
            " 68% 57/84 [01:02<00:30,  1.11s/it]\u001b[A\n",
            " 69% 58/84 [01:03<00:28,  1.11s/it]\u001b[A\n",
            " 70% 59/84 [01:04<00:27,  1.11s/it]\u001b[A\n",
            " 71% 60/84 [01:05<00:26,  1.11s/it]\u001b[A\n",
            " 73% 61/84 [01:06<00:25,  1.11s/it]\u001b[A\n",
            " 74% 62/84 [01:08<00:24,  1.11s/it]\u001b[A\n",
            " 75% 63/84 [01:09<00:23,  1.11s/it]\u001b[A\n",
            " 76% 64/84 [01:10<00:22,  1.11s/it]\u001b[A\n",
            " 77% 65/84 [01:11<00:21,  1.11s/it]\u001b[A\n",
            " 79% 66/84 [01:12<00:20,  1.11s/it]\u001b[A\n",
            " 80% 67/84 [01:13<00:18,  1.11s/it]\u001b[A\n",
            " 81% 68/84 [01:14<00:17,  1.11s/it]\u001b[A\n",
            " 82% 69/84 [01:15<00:16,  1.11s/it]\u001b[A\n",
            " 83% 70/84 [01:16<00:15,  1.12s/it]\u001b[A\n",
            " 85% 71/84 [01:18<00:14,  1.12s/it]\u001b[A\n",
            " 86% 72/84 [01:19<00:13,  1.12s/it]\u001b[A\n",
            " 87% 73/84 [01:20<00:12,  1.12s/it]\u001b[A\n",
            " 88% 74/84 [01:21<00:11,  1.12s/it]\u001b[A\n",
            " 89% 75/84 [01:22<00:10,  1.12s/it]\u001b[A\n",
            " 90% 76/84 [01:23<00:08,  1.11s/it]\u001b[A\n",
            " 92% 77/84 [01:24<00:07,  1.11s/it]\u001b[A\n",
            " 93% 78/84 [01:25<00:06,  1.11s/it]\u001b[A\n",
            " 94% 79/84 [01:26<00:05,  1.11s/it]\u001b[A\n",
            " 95% 80/84 [01:28<00:04,  1.11s/it]\u001b[A\n",
            " 96% 81/84 [01:29<00:03,  1.11s/it]\u001b[A\n",
            " 98% 82/84 [01:30<00:02,  1.11s/it]\u001b[A\n",
            " 99% 83/84 [01:31<00:01,  1.11s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2150205373764038, 'eval_runtime': 93.4133, 'eval_samples_per_second': 3.586, 'eval_steps_per_second': 0.899, 'epoch': 2.0}\n",
            " 67% 318/477 [1:21:01<38:49, 14.65s/it]\n",
            "100% 84/84 [01:32<00:00,  1.06s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-318\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-318/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-318/special_tokens_map.json\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/special_tokens_map.json\n",
            "{'loss': 1.5713, 'learning_rate': 2.648640465036316e-05, 'epoch': 2.01}\n",
            "{'loss': 1.566, 'learning_rate': 2.500000000000001e-05, 'epoch': 2.04}\n",
            "{'loss': 1.5938, 'learning_rate': 2.3542492430575753e-05, 'epoch': 2.07}\n",
            "{'loss': 1.5522, 'learning_rate': 2.2115566650658536e-05, 'epoch': 2.1}\n",
            "{'loss': 1.6187, 'learning_rate': 2.0720872019838566e-05, 'epoch': 2.14}\n",
            "{'loss': 1.5252, 'learning_rate': 1.9360020642261156e-05, 'epoch': 2.17}\n",
            "{'loss': 1.5761, 'learning_rate': 1.803458550322244e-05, 'epoch': 2.2}\n",
            "{'loss': 1.5592, 'learning_rate': 1.6746098650982072e-05, 'epoch': 2.23}\n",
            "{'loss': 1.5349, 'learning_rate': 1.549604942589441e-05, 'epoch': 2.26}\n",
            "{'loss': 1.5436, 'learning_rate': 1.4285882738904822e-05, 'epoch': 2.29}\n",
            "{'loss': 1.5445, 'learning_rate': 1.311699740140146e-05, 'epoch': 2.32}\n",
            "{'loss': 1.5835, 'learning_rate': 1.1990744508352602e-05, 'epoch': 2.35}\n",
            "{'loss': 1.5289, 'learning_rate': 1.090842587659851e-05, 'epoch': 2.39}\n",
            "{'loss': 1.5876, 'learning_rate': 9.871292540103377e-06, 'epoch': 2.42}\n",
            "{'loss': 1.543, 'learning_rate': 8.88054330390593e-06, 'epoch': 2.45}\n",
            "{'loss': 1.5677, 'learning_rate': 7.937323358440935e-06, 'epoch': 2.48}\n",
            "{'loss': 1.5955, 'learning_rate': 7.0427229558327036e-06, 'epoch': 2.51}\n",
            "{'loss': 1.5599, 'learning_rate': 6.1977761496908705e-06, 'epoch': 2.54}\n",
            "{'loss': 1.5758, 'learning_rate': 5.403459599865307e-06, 'epoch': 2.57}\n",
            "{'loss': 1.5789, 'learning_rate': 4.660691443541282e-06, 'epoch': 2.61}\n",
            "{'loss': 1.5501, 'learning_rate': 3.970330233980069e-06, 'epoch': 2.64}\n",
            "{'loss': 1.5984, 'learning_rate': 3.3331739481316624e-06, 'epoch': 2.67}\n",
            "{'loss': 1.5692, 'learning_rate': 2.7499590642665774e-06, 'epoch': 2.7}\n",
            "{'loss': 1.5534, 'learning_rate': 2.221359710692961e-06, 'epoch': 2.73}\n",
            "{'loss': 1.5861, 'learning_rate': 1.747986886543007e-06, 'epoch': 2.76}\n",
            "{'loss': 1.5342, 'learning_rate': 1.3303877555292443e-06, 'epoch': 2.79}\n",
            "{'loss': 1.5374, 'learning_rate': 9.69045013487252e-07, 'epoch': 2.83}\n",
            "{'loss': 1.5539, 'learning_rate': 6.643763304355566e-07, 'epoch': 2.86}\n",
            "{'loss': 1.5377, 'learning_rate': 4.167338677979027e-07, 'epoch': 2.89}\n",
            "{'loss': 1.5467, 'learning_rate': 2.2640387134577058e-07, 'epoch': 2.92}\n",
            "{'loss': 1.627, 'learning_rate': 9.360634033165338e-08, 'epoch': 2.95}\n",
            "{'loss': 1.5644, 'learning_rate': 1.8494773195648628e-08, 'epoch': 2.98}\n",
            "100% 477/477 [1:59:56<00:00, 14.65s/it]***** Running Evaluation *****\n",
            "  Num examples = 335\n",
            "  Batch size = 4\n",
            "\n",
            "  0% 0/84 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/84 [00:01<00:45,  1.80it/s]\u001b[A\n",
            "  4% 3/84 [00:02<01:03,  1.27it/s]\u001b[A\n",
            "  5% 4/84 [00:03<01:12,  1.10it/s]\u001b[A\n",
            "  6% 5/84 [00:04<01:17,  1.02it/s]\u001b[A\n",
            "  7% 6/84 [00:05<01:20,  1.03s/it]\u001b[A\n",
            "  8% 7/84 [00:06<01:21,  1.05s/it]\u001b[A\n",
            " 10% 8/84 [00:07<01:21,  1.07s/it]\u001b[A\n",
            " 11% 9/84 [00:08<01:21,  1.09s/it]\u001b[A\n",
            " 12% 10/84 [00:10<01:21,  1.10s/it]\u001b[A\n",
            " 13% 11/84 [00:11<01:20,  1.10s/it]\u001b[A\n",
            " 14% 12/84 [00:12<01:19,  1.11s/it]\u001b[A\n",
            " 15% 13/84 [00:13<01:18,  1.11s/it]\u001b[A\n",
            " 17% 14/84 [00:14<01:17,  1.11s/it]\u001b[A\n",
            " 18% 15/84 [00:15<01:16,  1.11s/it]\u001b[A\n",
            " 19% 16/84 [00:16<01:15,  1.11s/it]\u001b[A\n",
            " 20% 17/84 [00:17<01:14,  1.11s/it]\u001b[A\n",
            " 21% 18/84 [00:18<01:13,  1.11s/it]\u001b[A\n",
            " 23% 19/84 [00:20<01:12,  1.11s/it]\u001b[A\n",
            " 24% 20/84 [00:21<01:11,  1.11s/it]\u001b[A\n",
            " 25% 21/84 [00:22<01:10,  1.12s/it]\u001b[A\n",
            " 26% 22/84 [00:23<01:09,  1.12s/it]\u001b[A\n",
            " 27% 23/84 [00:24<01:08,  1.12s/it]\u001b[A\n",
            " 29% 24/84 [00:25<01:06,  1.12s/it]\u001b[A\n",
            " 30% 25/84 [00:26<01:05,  1.12s/it]\u001b[A\n",
            " 31% 26/84 [00:27<01:04,  1.12s/it]\u001b[A\n",
            " 32% 27/84 [00:28<01:03,  1.12s/it]\u001b[A\n",
            " 33% 28/84 [00:30<01:02,  1.12s/it]\u001b[A\n",
            " 35% 29/84 [00:31<01:01,  1.12s/it]\u001b[A\n",
            " 36% 30/84 [00:32<01:00,  1.12s/it]\u001b[A\n",
            " 37% 31/84 [00:33<00:59,  1.12s/it]\u001b[A\n",
            " 38% 32/84 [00:34<00:58,  1.12s/it]\u001b[A\n",
            " 39% 33/84 [00:35<00:56,  1.12s/it]\u001b[A\n",
            " 40% 34/84 [00:36<00:55,  1.12s/it]\u001b[A\n",
            " 42% 35/84 [00:37<00:54,  1.12s/it]\u001b[A\n",
            " 43% 36/84 [00:39<00:53,  1.12s/it]\u001b[A\n",
            " 44% 37/84 [00:40<00:52,  1.12s/it]\u001b[A\n",
            " 45% 38/84 [00:41<00:51,  1.12s/it]\u001b[A\n",
            " 46% 39/84 [00:42<00:50,  1.12s/it]\u001b[A\n",
            " 48% 40/84 [00:43<00:49,  1.11s/it]\u001b[A\n",
            " 49% 41/84 [00:44<00:47,  1.11s/it]\u001b[A\n",
            " 50% 42/84 [00:45<00:46,  1.11s/it]\u001b[A\n",
            " 51% 43/84 [00:46<00:45,  1.12s/it]\u001b[A\n",
            " 52% 44/84 [00:47<00:44,  1.12s/it]\u001b[A\n",
            " 54% 45/84 [00:49<00:43,  1.12s/it]\u001b[A\n",
            " 55% 46/84 [00:50<00:42,  1.11s/it]\u001b[A\n",
            " 56% 47/84 [00:51<00:41,  1.11s/it]\u001b[A\n",
            " 57% 48/84 [00:52<00:40,  1.11s/it]\u001b[A\n",
            " 58% 49/84 [00:53<00:39,  1.11s/it]\u001b[A\n",
            " 60% 50/84 [00:54<00:37,  1.11s/it]\u001b[A\n",
            " 61% 51/84 [00:55<00:36,  1.11s/it]\u001b[A\n",
            " 62% 52/84 [00:56<00:35,  1.11s/it]\u001b[A\n",
            " 63% 53/84 [00:57<00:34,  1.11s/it]\u001b[A\n",
            " 64% 54/84 [00:59<00:33,  1.11s/it]\u001b[A\n",
            " 65% 55/84 [01:00<00:32,  1.11s/it]\u001b[A\n",
            " 67% 56/84 [01:01<00:31,  1.11s/it]\u001b[A\n",
            " 68% 57/84 [01:02<00:30,  1.11s/it]\u001b[A\n",
            " 69% 58/84 [01:03<00:28,  1.11s/it]\u001b[A\n",
            " 70% 59/84 [01:04<00:27,  1.11s/it]\u001b[A\n",
            " 71% 60/84 [01:05<00:26,  1.11s/it]\u001b[A\n",
            " 73% 61/84 [01:06<00:25,  1.11s/it]\u001b[A\n",
            " 74% 62/84 [01:08<00:24,  1.11s/it]\u001b[A\n",
            " 75% 63/84 [01:09<00:23,  1.11s/it]\u001b[A\n",
            " 76% 64/84 [01:10<00:22,  1.11s/it]\u001b[A\n",
            " 77% 65/84 [01:11<00:21,  1.11s/it]\u001b[A\n",
            " 79% 66/84 [01:12<00:20,  1.11s/it]\u001b[A\n",
            " 80% 67/84 [01:13<00:18,  1.11s/it]\u001b[A\n",
            " 81% 68/84 [01:14<00:17,  1.11s/it]\u001b[A\n",
            " 82% 69/84 [01:15<00:16,  1.12s/it]\u001b[A\n",
            " 83% 70/84 [01:16<00:15,  1.12s/it]\u001b[A\n",
            " 85% 71/84 [01:18<00:14,  1.12s/it]\u001b[A\n",
            " 86% 72/84 [01:19<00:13,  1.12s/it]\u001b[A\n",
            " 87% 73/84 [01:20<00:12,  1.12s/it]\u001b[A\n",
            " 88% 74/84 [01:21<00:11,  1.12s/it]\u001b[A\n",
            " 89% 75/84 [01:22<00:10,  1.11s/it]\u001b[A\n",
            " 90% 76/84 [01:23<00:08,  1.11s/it]\u001b[A\n",
            " 92% 77/84 [01:24<00:07,  1.11s/it]\u001b[A\n",
            " 93% 78/84 [01:25<00:06,  1.11s/it]\u001b[A\n",
            " 94% 79/84 [01:26<00:05,  1.11s/it]\u001b[A\n",
            " 95% 80/84 [01:28<00:04,  1.12s/it]\u001b[A\n",
            " 96% 81/84 [01:29<00:03,  1.12s/it]\u001b[A\n",
            " 98% 82/84 [01:30<00:02,  1.12s/it]\u001b[A\n",
            " 99% 83/84 [01:31<00:01,  1.11s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 1.2081540822982788, 'eval_runtime': 93.4185, 'eval_samples_per_second': 3.586, 'eval_steps_per_second': 0.899, 'epoch': 3.0}\n",
            "100% 477/477 [2:01:30<00:00, 14.65s/it]\n",
            "100% 84/84 [01:32<00:00,  1.06s/it]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-477\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-477/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/tmp-checkpoint-477/special_tokens_map.json\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 7303.7891, 'train_samples_per_second': 1.046, 'train_steps_per_second': 0.065, 'train_loss': 1.7024600490833979, 'epoch': 3.0}\n",
            "100% 477/477 [2:01:41<00:00, 15.31s/it]\n",
            "Waiting for the current checkpoint push to be finished, this might take a couple of minutes.\n",
            "Saving model checkpoint to OpenHathi-7B-Hi-v0.1-Instruct\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/special_tokens_map.json\n",
            "Saving model checkpoint to OpenHathi-7B-Hi-v0.1-Instruct\n",
            "tokenizer config file saved in OpenHathi-7B-Hi-v0.1-Instruct/tokenizer_config.json\n",
            "Special tokens file saved in OpenHathi-7B-Hi-v0.1-Instruct/special_tokens_map.json\n",
            "Dropping the following result as it does not have all the necessary fields:\n",
            "{'dataset': {'name': 'generator', 'type': 'generator', 'config': 'default', 'split': 'train', 'args': 'default'}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime █▁▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▃███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▇▅▄▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.20815\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 93.4185\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 3.586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.899\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.5644\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 6.274475756554813e+17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.70246\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 7303.7891\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1.046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.065\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvaliant-donkey-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/smangrul/openhathi_instruct/runs/gde27ixu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/smangrul/openhathi_instruct/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNTEwNjE5MQ==/version_details/v3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231222_050918-gde27ixu/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJGpdE19EPbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}